-# Reading Data Advanced

## Index

Quickly you will realize that `filter` is slow. If you have a table
with more than 100,000 records, `filter` stops working. All of that is becuase
we haven't used index yet. Without index, we cannot even order data

    r.db("foodb").table("compounds_foods").orderBy(r.desc("id"))
    #->
    RqlRuntimeError: Array over size limit `100000` in:
    r.db("foodb").table("compounds_foods").orderBy(r.desc("id"))
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Without an index, RethinkDB hold all data in memory and sort or filter in
memory. A limit has to lie somewhere else. That 100,000 the magic number of the limit
RethinkDB set to read data without index.


To properpely fetching data, we have to create an Index. And really, in real application, we almost always endup creating index on MySQL  to fetch data efficiently. 

We have two kind of indexes in RethinkDB

* primary index: our ID key is this. This index is created automatically by
RethinkDB. Coming back above query, if we change it to use primary `index`

    r.db("foodb").table("compounds_foods").orderBy({index: r.desc("id")})

`id` field is always indexed automatically.

* secondary index:

Seconday index is the index we created ourselve on one or many fields. Secondary
index can be simple, just index the value of fields directly, or doing some
pre-calculate on data before indexing.

While index helps to decrease the reading time, it decreases writing time, also cost
storage space. It reduces write performance becuase whenever we inserted a
document, the index has to be calculate and writing into the database.

RethinkDB supports those kinds of index:

*Simple
:indexes based on the value of a single field.
*Compound
:indexes based on multiple fields.
*Multi 
:indexes based on arrays of values.
*Indexes 
:based on arbitrary expressions.

So now you know what index is. But a sad news is that filter cannot use those secondary index. FOr that purpose we have to use other functions: `getAll` and `between`. 
### Creating index

Let's start with simple index first.

## Simple index

As its name, simple index is simply a single field. Let's say we want to find all `compounds_foods` whose name contains `banana`. We cannot use `filter` here because this table has more than 100,000 item. `filter` also doesn't use index. Let's meet `getAll`. `getAll` grabs all document where a given key match the index which we specified.

First, we create index follow this syntax

    table.index_create(index_name[, index_function][, :multi => false]) → object

Apply it on our case, for a single column:

    r.db("foodb")
      .table("compounds_foods")
      .indexCreate("match_orig_food_common_name", r.row.match)

If we don't pass an index function, RethinkDB try to create index for the column of same name as requested index name.

Time to use it:

    r.db("foodb")
      .table("compounds_foods")
      .getAll('Bananas', {index:'orig_food_common_name'})
    #=> Executed in 10ms. No results returned.

No result. Strange, we cannot believe we have no document where its
orig_food_common_name doesn't contain banana. Why so? Well, the simple
index does an exact match, or in other world, it's an equal comparison.
Let's try an exact match:

    r.db("foodb")
      .table("compounds_foods")
      .getAll('Bananas, raw', {index:'orig_food_common_name'})
    #=> Executed in 69ms. 40 rows returned, 40 displayed, more available
    {
    "citation":  "USDA" ,
    "citation_type":  "DATABASE" ,
    "compound_id": 2100 ,
    "created_at": Tue Jan 03 2012 18:33:15 GMT-08:00 ,
    "creator_id": null ,
    "food_id": 208 ,
    "id": 257686 ,
    "orig_citation": null ,
    "orig_compound_id":  "262" ,
    "orig_compound_name":  "Caffeine" ,
    "orig_content":  "0.0" ,
    "orig_food_common_name":  "Bananas, raw" ,
    "orig_food_id":  "09040" ,
    "orig_food_part": null ,
    "orig_food_scientific_name": null ,
    "orig_max": null ,
    "orig_method": null ,
    "orig_min": null ,
    "orig_unit":  "mg" ,
    "orig_unit_expression": null ,
    "updated_at": Tue Jan 03 2012 18:33:15 GMT-08:00 ,
    "updater_id": null
    }

We can pass multiple keys to `getAll` to have an `or` effect. Meaning RethinkDB
returns document where the index match any of value that we pass.

    r.db("foodb")
      .table("compounds_foods")
      .getAll('Bananas, raw', 'Yoghurt with pear and banana', 'Alfalfa seeds',{index:'orig_food_common_name'})

We can chain to `count` to count how many document we have

    r.db("foodb")
      .table("compounds_foods")
      .getAll('Bananas, raw', 'Yoghurt with pear and banana', 'Alfalfa seeds',{index:'orig_food_common_name'})
      .count()
    #=> 256

Not only use to find document, index can be used for sorting as well. To sort,
we call `orderBy` and passing index name.

    r.db("foodb").table("compounds_foods")
      .orderBy({index: "orig_food_common_name"})

When passing index, we can wrap it in other expression to change ordering:

    r.db("foodb").table("compounds_foods")
      .orderBy({index: r.desc("orig_food_common_name")})
      .withFields("orig_food_common_name")
    #=> 
    {
    "orig_food_common_name":  "Zwieback"
    } {
    "orig_food_common_name":  "Zwieback"
    } {
    "orig_food_common_name":  "Zwieback"
    }

Using `withFields`, we can pass a list of field to choose what we want to get
back.

Because index can be used to sort, we can use it to find the value between a
range. In RethinkDB, `between` syntax is:

    table.between(lowerKey, upperKey[, {index: 'id', leftBound: 'closed',
rightBound: 'open'}]) → selection

As you see, we can only use between on table type. So, note that.
Use this we can find the document between "Apple" and "Banana" range.

    r.db("foodb").table("compounds_foods")
      .between("Apple", "Banana", {index: 'orig_food_common_name'})
      .orderBy({index: r.desc("orig_food_common_name")})
      .withFields("orig_food_common_name")

Without specifying an index, `between` operates on primary index. Many RethinkDB 
function has same behaviour

    r.db("foodb").table("compounds_foods")
      .between(1, 200)
      .count()
    #=> 198

This work when we want to find data based on a single field. How about find
value base on multiple field. Let's meet compound index

## Compound index

Compound index is created by using value of multiple fields. It's very similar to
single index in syntax, just different on how many fields we pass to index
create. Let's look at `compounds_foods` table, it contains relation ship of
`foods` and `compounds`. We will learn more about JOIN later. For now, let's say
we want to find all `compounds_foods` document where its `compound_id` is 3524
and `food_id` is 287. We are finding on two columnds, so we need an index
contains those 2 columns:

    r.db("foodb").table("compounds_foods")
      .indexCreate("compound_food_id", [r.row(row"compound_id"), r.row("food_id")]) 

The only different with simple index is we have to pass an array of field to
create index. Let's try it:

    r.db("foodb").table("compounds_foods")
      .getAll([354,287], {index: 'compound_food_id'})
    #=>
    RqlRuntimeError: Index `compound_food_id` on table `foodb.compounds_foods` was
    accessed before its construction was finished in:
    r.db("foodb").table("compounds_foods").getAll([354, 287], {index:
    "compound_food_id"})
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We got an error. Looks like the index is not completed created yet. The table
has 

We can query index status:

    r.db("foodb").table("compounds_foods")
      .indexStatus('compound_food_id')
    #=>
    [
    {
    "blocks_processed": 13192 ,
    "blocks_total": 15437 ,
    "function": <binary, 408 bytes, "24 72 65 71 6c 5f..."> ,
    "geo": false ,
    "index":  "compound_food_id" ,
    "multi": false ,
    "outdated": false ,
    "ready": false
    }
    ]

The field ready is false. We can only wait until it finish. This table is very
big. We can verify:

    r.db("foodb").table("compounds_foods").count()
    #=> 737089

Let's just wait for bit, make a cup of coffee and come back :). When it's ready
you should see:

    r.db("foodb").table("compounds_foods")
      .indexStatus('compound_food_id')

    [
    {
    "function": <binary, 408 bytes, "24 72 65 71 6c 5f..."> ,
    "geo": false ,
    "index":  "compound_food_id" ,
    "multi": false ,
    "outdated": false ,
    "ready": true
    }
    ]

Now, try it:
    
    r.db("foodb").table("compounds_foods")
      .getAll([21477,899], {index: 'compound_food_id'})
    #=> Executed in 7ms. 1 row returned
    {
    "citation":  "DFC CODES" ,
    "citation_type":  "DATABASE" ,
    "compound_id": 21477 ,
    "created_at": Tue Sep 11 2012 16:12:30 GMT-07:00 ,
    "creator_id": null ,
    "food_id": 899 ,
    "id": 740574 ,
    "orig_citation": null ,
    "orig_compound_id": null ,
    "orig_compound_name": null ,
    "orig_content": null ,
    "orig_food_common_name":  "Meats" ,
    "orig_food_id":  "WI8000" ,
    "orig_food_part": null ,
    "orig_food_scientific_name": null ,
    "orig_max": null ,
    "orig_method": null ,
    "orig_min": null ,
    "orig_unit": null ,
    "orig_unit_expression": null ,
    "updated_at": Tue Sep 11 2012 16:12:30 GMT-07:00 ,
    "updater_id": null
    }

With above indexing approach, you found that you have to crate a dedicated index
for whatever you want to find. An index contains a single value for a document:
either a single value of field, or an order set of value in case of compound
index. But life is not that simple. Let's looking at `users` table. It contains
a list of user and their three of most faviroute food, store in field
`favfoods`. That's a single column. But it hold many elements. Because of that,
we cannot simple answer the question who liked `Mushroom`:

let's create an index

    r.db("foodb").table("users").indexCreate('favfoods')

Try to find all user who liked mushrooms.

    r.db("foodb").table("users")
      .getAll('Mushrooms', {index: 'favfoods'})
    #=> Executed in 6ms. No results returned.

Why so? Because we index the whole field as a single value, we have to match the
whole value of field:

    r.db("foodb").table("users")
      .getAll(["Edible shell" ,
        "Clupeinae (Herring, Sardine, Sprat)" ,
        "Deer" ,
        "Perciformes (Perch-like fishes)" ,
        "Bivalvia (Clam, Mussel, Oyster)"], {index: 'favfoods'})
    #=>
    {
    "favfoods": [
    "Edible shell" ,
    "Clupeinae (Herring, Sardine, Sprat)" ,
    "Deer" ,
    "Perciformes (Perch-like fishes)" ,
    "Bivalvia (Clam, Mussel, Oyster)"
    ] ,
    "id":  "1dd8059c-82ca-4345-9d75-eaa0f8edbf48" ,
    "name":  "Arthur Hegmann"
    }

*Multi index* is used to solve above question: who likes Banana. An multi index
is used on multiple value, or in other word, an array of value. When RethinkDB
see that we want to use a *multi index*, it try to loop over all value in the
array of index, and match to each of element of array.

To create a multi index, all we have to do is pass the option flag:` multi:
true`


    r.db("foodb").table("users").indexCreate('favfoods_multi', r.row("favfoods"), {multi: true})

Now, try it:

    r.db("foodb").table("users")
      .getAll('Mushrooms', {index: 'favfoods_multi'})
    #=>
    {
    "favfoods": [
    "Milk substitute" ,
    "Mushrooms" ,
    "Nuts" ,
    "Hummus" ,
    "Soft-necked garlic"
    ] ,
    "id":  "47110a8f-3c2c-46b8-96d8-244747c1818b" ,
    "name":  "Annabelle Lindgren"
    }

If you notice, we have to pass `r.row(favfoods)` to create an index. Remember
that to create an index where its name doesn't match any field, we have to pass
an expression or an anonymous fuction to `indexCreate` to caculate its value.
But we defined `favfoods` index before, so now we cannot create other index with
same name. Can we go back, delete index to clear thing up and save our
namespace:

    r.db("foodb").table("users").indexDrop('favfoods')
    #=> 
    { "dropped": 1 } 
    r.db("foodb").table("users").indexDrop('favfoods_multi')
    #=> 
    { "dropped": 1 } 

Now, let create an multile index with same field name:

    r.db("foodb").table("users").indexCreate('favfoods', {multi: true})
    r.db("foodb").table("users").getAll('Mushrooms', {index: 'favfoods'})
    #=>
    {
    "favfoods": [
    "Milk substitute" ,
    "Mushrooms" ,
    "Nuts" ,
    "Hummus" ,
    "Soft-necked garlic"
    ] ,
    "id":  "47110a8f-3c2c-46b8-96d8-244747c1818b" ,
    "name":  "Annabelle Lindgren"
    }

Another question come up? Can we find all user who like `Mustrooms` and
`Banana`. We may try this:

    r.db("foodb").table("users")
      .getAll('Kiwi', 'Banana', {index: 'favfoods'})

However, that's an `or`. RethinkDB will return documents where its index value
matches either `Kiwi` or `Banana`.

Even more complex, we want to find user who like Kiwi most. Meaning `kiwi` has
to be first element in ther *favfoods* array.

To do that, we see that we are passing business logic into RethinkDB. We have to
somehow represent that logic in RethinkDB, calculate the value, and index the
return value. Let's meet `arbitrary expressions` index. 

## Arbitray expressions index

As its name, the returned value of expression is used to calculate index.

Unfortunately at this moment, we cannot simple answer who like both of banana
and kiwi. We will save it for later chapter when we learn about `map` function.
Now, let's find user
who like kiwi most. With assumption that the first element of `favfoods` array
is what an user like most.

    r.db("foodb").table("users")
      .indexCreate('most-favourite-food', function (user) {
        return user("favfoods").nth(0)
      })

Given an array, `nth(n)` return n-th element. We call `nth(0)` on array
`favfoods`  that means first
element of array since they are zero-base index.

    r.db("foodb").table("users")
      .getAll('Kiwi', {index: 'most-favourite-food-1'})
    #=>
    {
    "favfoods": [
    "Kiwi" ,
    "Lemon" ,
    "Lime" ,
    "Coffee" ,
    "Sweet orange"
    ] ,
    "id":  "0b83164e-fb42-4273-8db1-ba12be6e580d" ,
    "name":  "Carl Achiban"
    } {
    "favfoods": [
    "Kiwi" ,
    "Banana" ,
    "Peanut" ,
    "Asparagus" ,
    "Common cabbage"
    ] ,
    "id":  "d10b51d7-d321-4b41-bd7d-1367ede0eb30" ,
    "name":  "Luma Ramses"
    }

This index is powerful because we can push more complex searching to database
engine. Let's say we want to find all user who like `Kiwi` most and is a female.

    r.db("foodb").table("users")
      .indexCreate('most-favourite-food-gender', function (user) {
        return [user("gender"), user("favfoods").nth(0)]
      })

Here, we are trying to create non-multi index. The index is an array of gender
and most like food item. Now, let's try our index

    r.db("foodb").table("users")
      .getAll(['f', 'Kiwi'], {index: 'most-favourite-food-gender'})
    #=>
    {
    "favfoods": [
    "Kiwi" ,
    "Lemon" ,
    "Lime" ,
    "Coffee" ,
    "Sweet orange"
    ] ,
    "gender":  "f" ,
    "id":  "0b83164e-fb42-4273-8db1-ba12be6e580d" ,
    "name":  "Carl Achiban"
    } {
    "favfoods": [
    "Kiwi" ,
    "Banana" ,
    "Peanut" ,
    "Asparagus" ,
    "Common cabbage"
    ] ,
    "gender":  "f" ,
    "id":  "d10b51d7-d321-4b41-bd7d-1367ede0eb30" ,
    "name":  "Luma Ramses"
    }

One thing I want to remind you(well, myself actually) is that the return
function in any RethinkDb expression is evaludated on RethinkDB, not on client
language. You cannot just write anything. You have to use RethinkDB expression
in return value so that RethinkDB can calculated it. In previous chapter, we
learn about `expr`, you can use that to turn native object into RethinkDb object
when wanting.

Let's look at this example:

    r.table("users").indexCreate("full_name2", function(user) {
        return r.add(user("last_name"), "_", user("first_name"))
    }).run(conn, callback)

We are trying to create an index by appending *last_name* and *first_name*. We
cannot write

    return user("last_name") + user("first_name")

because ReThinkDB won't understand that expression. We have to call `r.add`
function.

However, even if you see something like 

    return user("last_name") + user("first_name")

That's doesn't mean RethinkDB understand your native expression. It's actually
your driver overload operator (`+` operator) in this case because your host
language apparently support operator overloading.

If you notice, we don't pass `multi: true` in any of above examples. Can we use
multi index with arbitray expression index? Yes, we can.

Let's say if we can find any users who like `Kiwi` or used to eat Kiwi. We will
create an multi index by concat array `favfoods` and `eatenfoods`


    r.db("foodb").table("users")
      .indexCreate(
        'eateen-or-like-multi', 
        r.add(r.row("eatenfoods"), r.row("favfoods"))
        , {multi: true})

Now, we can use that index:


    r.db("foodb").table("users")
      .getAll('Kiwi', {index:'eateen-or-like-multi'})
    #=>
    {
    "eatenfoods": [
    "Celery leaves" ,
    "Kiwi" ,
    "Rainbow trout" ,
    "Chinese bayberry" ,
    "Hyacinth bean" ,
    "Other sandwich"
    ] ,
    "favfoods": [
    "Honey" ,
    "Cake" ,
    "Butter substitute" ,
    "Cream" ,
    "Sugar"
    ] ,
    "gender":  "m" ,
    "id":  "808cedd5-f2ac-4724-98bc-061ee84755c9" ,
    "name":  "Forrest Jacobs"
    } {
    "eatenfoods": [
    "Jerusalem artichoke" ,
    "Conch" ,
    "Milk and milk products" ,
    "Dumpling" ,
    "Custard apple" ,
    "Sacred lotus" ,
    "Japanese walnut" ,
    "Crab"
    ] ,
    "favfoods": [
    "Kiwi" ,
    "Banana" ,
    "Peanut" ,
    "Asparagus" ,
    "Common cabbage"
    ] ,
    "gender":  "f" ,
    "id":  "d10b51d7-d321-4b41-bd7d-1367ede0eb30" ,
    "name":  "Luma Ramses"
    }
    
How about finding user liked Kiwi most and have eaten kiwi? We just need to
change the index function, this time we will use anonymous function:

    r.db("foodb").table("users")
      .indexCreate(
        'eatean-or-like-most',
        function (user) {
          return r.add(user("eatenfoods"), [user("favfoods").nth(0)])
        }
        , {multi: true})

Really, function is just a special case of expression where expression is
result of function executing. Now, we can try to find:

    r.db("foodb").table("users")
      .getAll('Kiwi', {index: 'eatean-or-like-most'})
    #=>
    {
        "eatenfoods": [
            "Shrimp",
            "Other fish product",
            "Sweet orange",
            "Unclassified food or beverage"
        ],
        "favfoods": [
            "Kiwi",
            "Lemon",
            "Lime",
            "Coffee",
            "Sweet orange"
        ],
        "gender": "f",
        "id": "0b83164e-fb42-4273-8db1-ba12be6e580d",
        "name": "Carl Achiban"
    } {
        "eatenfoods": [
            "Celery leaves",
            "Kiwi",
            "Rainbow trout",
            "Chinese bayberry",
            "Hyacinth bean",
            "Other sandwich"
        ],
        "favfoods": [
            "Honey",
            "Cake",
            "Butter substitute",
            "Cream",
            "Sugar"
        ],
        "gender": "m",
        "id": "808cedd5-f2ac-4724-98bc-061ee84755c9",
        "name": "Forrest Jacobs"
    } {
        "eatenfoods": [
            "Jerusalem artichoke",
            "Conch",
            "Milk and milk products",
            "Dumpling",
            "Custard apple",
            "Sacred lotus",
            "Japanese walnut",
            "Crab"
        ],
        "favfoods": [
            "Kiwi",
            "Banana",
            "Peanut",
            "Asparagus",
            "Common cabbage"
        ],
        "gender": "f",
        "id": "d10b51d7-d321-4b41-bd7d-1367ede0eb30",
        "name": "Luma Ramses"
    }



## Checking index status

As I said above, indexing reduces write performance, therefore it takes time to
create after we issue creating command. Depend on the table size, how many
records we have, we have to wait for an amout of time before using it. We can
check the status of an index to see if it's ready to use

    r.table().indexStatus(indexName)

Such as:

    r.db("foodb").table("compounds_foods").indexStatus("food_id")
    #=> 
    {
    "blocks_processed": 656 ,
    "blocks_total": 11331 ,
    "function": <binary, 181 bytes, "24 72 65 71 6c 5f..."> ,
    "geo": false ,
    "index":  "food_id" ,
    "multi": false ,
    "outdated": false ,
    "ready": false
    }

The `ready` field indicate if the index is ready to use.

Sometimes we just want to say, when the index is ready, please run this:

    r.table.indexWait


## Using index

### Order

Sorting with order without index limit to 100k issue

### Pagination

To pagination data, we will use a a combination of `skip`, `limit` and `slice`.

**skip(n)**

: Skip a number of element from the begining of sequence or array

**limit(n)**

: End the sequence after we read up to the give number of limit

**slice

T> ## Where else I can call Skip, Limit, Slice
T>
T> These command can be called on a selection, an array or stream. So you ca

## Transform data

So far, we always take the value that return from RethinkDB to work with it? In
any real application, you prolly want to do some transform around it. If we do
it at applcation level, for complex thing, it make sense. But for simple thing,
we may waste another extra loop. Or sometime we want to do thing at RethinkDB
level, or we want to use transform data in other ReQL expression.

An example is the function `nth` or `count`. We call them on a sequence, or an
array of data, and they return a different data. They transform original data
into a different piece of data. But `nth` and `count` are simple function. They
don't have any complex logic inside them. Some transform function has complex
logic. With those logic, we have to use some kind of `if ...else...` command, or
loop. To help us with that, RethinkDB has some control structure functions such
as `branch` (similar to `if`) or `forEach`, `do`. RethinkDb shines in those
area because database engine now seems has an embedded language in it.

Let's cover more of those functions. Along the way we learn somne structure
control command. Now, move on to our next function, **map**.

### Map

Let's say we want to divide our users into 3 groups, who are under 18 years old
are **teenager**, between 18-50 are **adult**, and over 50 years old are
**older**. We have a pattern here, with each of document in table, we want to
calculate a new data, depend on their existed data. In RethinkDB, we used
***map*** function.

Map apply a function on document, and return value of fuction is returned from
query. With our example, in a normal programming language, such as Ruby we can
write:

    users.map do |user|
      if user["age"] <= 18
        "teenager"
      else if user["age"] >18 && user["age"] <50 
        "adult"
      else
        "older"
      end
    end

In RethinkDB, the format of map is:

    sequence1.map([sequence2, ...], mappingFunction) → stream
    array1.map([array2, ...], mappingFunction) → array
    r.map(sequence1[, sequence2, ...], mappingFunction) → stream
    r.map(array1[, array2, ...], mappingFunction) → array

With our example, we have to represent `if` in RethinkDB function. We do that
with `branch`:

    r.branch(test, true_branch, false_branch) → any

Time to write our function:

    r.db("foodb").table("users").map(function (user) {
      return r.branch(
        user("age").lt(18),
        "teenager",
        r.branch(
          user("age").gt(50),
          "older",
          "adult"
        )
      )
    })
    #=>
    "older" "older" "older" "adult" "older" "older" "older" "adult" "older"
    "older" "older" "adult" "teenager" "adult" "adult" "adult" "older" "adult"
    "older" "older" "older" "older" "adult" "teenager" "adult" "older" "older"
    "older" "older" "adult" "adult" "older" "adult" "older" "older" "older" "adult"
    "older" "older" "older"

Yay, we get what we want. But it only return the value from fuction, we don't
know who is who. Well, that's `map` job. It transform the whole document into
the return value. How about we return an object, with original `name` field, and
our `group` field, like this:

    r.db("foodb").table("users").map(function (user) {
      return {
        name: user("name"), 
        group: r.branch(
        user("age").lt(18),
        "teenager",
        r.branch(
          user("age").gt(50),
          "older",
          "adult"
        )
        )}
    })
    #=>
    {
    "group":  "adult" ,
    "name":  "Arthur Hegmann"
    } {
    "group":  "older" ,
    "name":  "Ricky Quigley Sr."
    } {
    "group":  "older" ,
    "name":  "Jazmyne Brakus"
    }
    ....


Great. But if we want to return whole document, with extra `group` field, do we
have to repeatedly write every fields. Well, let's meet `merge`.

    r.db("foodb").table("users").map(function (user) {
      return user.merge({
        group: r.branch(
          user("age").lt(18),
          "teenager",
          r.branch(
            user("age").gt(50),
            "older",
            "adult"
          )
        )})
    })

If you question can we use `row` in `map` expression instead of using function.
Yes, we can. But we cannot in above example. Because `row` doesn't work in
nested query. In above example. we nested `r.branch` inside `merge`, and inside
other `branch`. 

Let's see an example where we can use `r.row`: couting how many foods they have
eaten:

    r.db("foodb").table("users").map({
      name: r.row("name"),
      total_eaten: r.row("eatenfoods").count()
    })
    #=>
    {
    "name":  "Arthur Hegmann" ,
    "total_eaten": 6
    } {
    "name":  "Ricky Quigley Sr." ,
    "total_eaten": 7
    }

By using `map`, we can pre-calculated some data, either using function or
expression. Let's meet other kind of `mapping` function.

### concatMap

***concatMap*** is very similar to map. It applies function to every element of
sequence. But it's different because it also try to flatten, or concat all
element into a single sequence.

    r.expr([1, 2, 3]).map(function(x) { return [x, x.mul(2)] })
    #=> [[1, 2], [2, 4], [3, 6]]

However, `concatMap` will concat all sub sequence/array into final return data.

    r.expr([1, 2, 3]).concatMap(function(x) { return [x, x.mul(2)] })
    #=> [1, 2, 2, 4, 3, 6]

When is it useful? It looks like very useless, right. Well, let's look at
`favfoods` field. If we want to get a list of `favfoods` on entire system, we
can do:

    r.db("foodb").table("users").map(
      r.row("favfoods")
    )
    #=>
    [
      "Garden tomato (var.)" ,
      "Linden" ,
      "Lowbush blueberry" ,
      "American cranberry" ,
      "Vanilla"
    ],
    [
      "Swiss chard" ,
      "Chicory roots" ,
      "Grapefruit" ,
      "Jostaberry" ,
      "Spirit"
    ]

Well, as expecting, we get an array of array. That's when `concapMap` shines:

    r.db("foodb").table("users").concatMap(
      r.row("favfoods")
    )
    #=>
    Pikeperch
    Pacific ocean perch
    True seal
    Columbidae (Dove, Pigeon)
    Conch
    Kiwi
    Lemon
    Lime
    Coffee
    Sweet orange
    Kiwi
    True seal
    Salmonidae (Salmon, Trout)
    ...

If you notice, we have duplicate data. That's natural because many users may
like same foods. To get distinct value, you can call `distinct` on the sequence:

    r.db("foodb").table("users").concatMap(
      r.row("favfoods")
    ).distinct()
    #=>
    [
    "Abalone" ,
    "Abiyuch" ,
    "Acerola" ,
    "Acorn" ,
    "Adobo" ,
    "Adzuki bean" ,
    ]

`distinct` accepts an index and use it to differentce document, without any
specified index, it uses primary index, or the `id` value, which is good enough
in our case, because we don't have foods with same name. Sometimes, you may want
to create extra index for the field and call `distinct` using that index.

Let's dig into more complex example. For each of foods, let's find all of its
compound.

Let's create an index first:

    r.db("foodb").table("compounds_foods").indexCreate("food_id")

With that index, we can try our query:

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .concatMap(function (food) {
        return 
          r.db("foodb").table("compounds_foods")
          .getAll(food("id"), {index: "food_id"})
          .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
          .map(function(compound_food) {
            return food.merge({compound: compound_food})
          })
      })
    #=>
    {
    "compound": {
    "compound_id": 21594 ,
    "food_id": 2 ,
    "id": 15609 ,
    "orig_compound_name":  "Fatty acids, total saturated" ,
    "orig_food_common_name":  "Cabbage, savoy, raw"
    } ,
    "id": 2 ,
    "name":  "Savoy cabbage"
    } {
    "compound": {
    "compound_id": 21595 ,
    "food_id": 2 ,
    "id": 15610 ,
    "orig_compound_name":  "Fatty acids, total mono-unsaturated" ,
    "orig_food_common_name":  "Cabbage, savoy, raw"
    } ,
    "id": 2 ,
    "name":  "Savoy cabbage"
    }

Note that we use some `withFields` command to limit on the fields that we want
to include in return document.

Above example won't work with `map`. Because the return value from function
isn't a single value, but another sequence. If you attempt to use `map`, you can
see error clearly:

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .map(function (food) {
        return 
          r.db("foodb").table("compounds_foods")
          .getAll(food("id"), {index: "food_id"})
          .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
          .map(function(compound_food) {
            return food.merge({compound: compound_food})
          })
      })
    #=> RqlRuntimeError: Expected type DATUM but found SEQUENCE:

`concatMap` can operator on sequence value from funciton, and try to flatten it
for us. Let's back to this and break down how it works:

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .concatMap(function (food) {
        return 
          r.db("foodb").table("compounds_foods")
          .getAll(food("id"), {index: "food_id"})
          .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
          .map(function(compound_food) {
            return food.merge({compound: compound_food})
          })
      })

For every documents of foods, it's transform into a document similar to this:

    [
      {id: id1, name: name1, compound: compound_food_document1}, 
      {id: id1, name: name1, compound: compound_food_document2},
      {id: id1, name: name1, compound: compound_food_documentn},a
    ]

That mean, with an sequence of foods, we will have this(without concatMap):

    [
      {id: id1, name: name1, compound: compound_food_document1}, 
      {id: id1, name: name1, compound: compound_food_document2},
      {id: id1, name: name1, compound: compound_food_documentn},...
    ],
    [
      {id: id2, name: name2, compound: compound_food_document1}, 
      {id: id2, name: name2, compound: compound_food_document2},
      {id: id2, name: name2, compound: compound_food_documentn},...
    ],
    ...

But concat map will fallten array and we have this:

    {id: id1, name: name1, compound: compound_food_document1}, 
    {id: id1, name: name1, compound: compound_food_document2},
    {id: id1, name: name1, compound: compound_food_documentn},...
    ,
    {id: id2, name: name2, compound: compound_food_document1}, 
    {id: id2, name: name2, compound: compound_food_document2},
    {id: id2, name: name2, compound: compound_food_documentn},...
    , ...

That's power of `concatMap`. We can use it to do a join effect. But one problem
remains, as you can see, we have many document with same `food` but different
compound of that food. Can we somehow compile them into an array like this:

    {id: id1, name: name1, 
      compound: [compound_food_document1, compound_food_document2, ...]
    },
    {id: id2, name: name2, 
      compound: [compound_food_documentn, compound_food_documentn, ...]
    },...

Let's tweak our `concatMap` a bit.

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .concatMap(function (food) {
        return [
          food.merge({compound: 
            r.db("foodb").table("compounds_foods")
            .getAll(food("id"), {index: "food_id"})
            .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
            .limit(10)
          })
        ]
      })

First off, you notice that we wrap food.merge in array. Why so? Because
`concatMap` expects return value from function is a sequence. `map` expects
return value from function is DATUM, likewise. We also call `limit(10)` on the
`compound_foods` sequence to limit first 10 result, sort by primary key, `id`
field of `compound_foods` table in this case.

Instead of create a map to loop over the `compound_foods` sequence and create a
document, we simply bring the whole `compound_foods` array to merge into
**food** document. Looks good, run this and here come the error:

    RqlRuntimeError: Expected type DATUM but found SEQUENCE:

Well, merge expect a `DATUM`. A datum is like a single primitive value. Such as
a number, an array. But we are passing SEQUENCE. You can understand that we are
expecting an primitive value, but we passed a cursor. Like in Ruby, when we
expect an array, but we pass an enumarator. In RethinkDB, to make this kind of
merge work, we have to explicitly convert it to an array, using `coerceTo` with
parameter **array**.

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .concatMap(function (food) {
        return [
          food.merge({compound: 
            r.db("foodb").table("compounds_foods")
            .getAll(food("id"), {index: "food_id"})
            .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
            .limit(10)
            .coerceTo('array')
          })
        ]
      })
    #=>
    {
    "compound": [ ... ] ,
    "id": 2 ,
    "name":  "Savoy cabbage"
    } {
    "compound": [ ... ] ,
    "id": 15 ,
    "name":  "Wild celery"
    }

Now, with `coerceTo` function, we know that we can convert sequence into
`array`. So can we achieve this with map, instead of `concatMap`. Yes, and it's even more
simpler:

    r.db("foodb")
      .table("foods")
      .withFields("id", "name")
      .map(function (food) {
        return
          food.merge({compound: 
            r.db("foodb").table("compounds_foods")
            .getAll(food("id"), {index: "food_id"})
            .withFields("id", "food_id", "compound_id", "orig_food_common_name",
    "orig_compound_name")
            .limit(10)
            .coerceTo('array')
          })
      })

We no longer have to wrap it in `[]` because `map` can work with OBJECT. With
this example, we see that `concatMap` and `map` sometime can be use
interchangably depend on how we want to model the data.

## Index and Map

I promised you an answer to quesiton who like both of Kiwi and banana. As you
can guest, we have to create a multi index with each of value is a pair of
favourite foods. It's very hard to do this without `map`. We prolly thinking of
two nested loops. With map, we can do this:


    r.db("foodb")
      .table("users")
      .indexCreate("food-test-idx-1", function (food) {
        return
          food("favfoods")
            .concatMap(function (favfood) {
              return
                food("favfoods").map(function (favfood2) {
                  return [favfood, favfood2]
                  })
            })
      }, {multi: true})

We will do a map. With each of element of `favfoods` we try to create a new
array of two element, by combine the element with each of element of `favfoods`
itself. We use `concatMap` to flatten array, and set `multi: true` because this
is a multi indexer: we are returning an array from index function.

And now, we can use that index, pass a pair of value:

    r.db("foodb")
      .table("users")
      .getAll(['Spirit', 'Grapefruit'], {index: "food-test-idx-1"})
    #=>
    {
    "age": 41 ,
    "eatenfoods": [
    "Hummus" ,
    "Common beet"
    ] ,
    "favfoods": [
    "Swiss chard" ,
    "Chicory roots" ,
    "Grapefruit" ,
    "Jostaberry" ,
    "Spirit"
    ] ,
    "gender":  "f" ,
    "id":  "3700fa48-2806-4cb2-9bfb-a5d90d6cfd38" ,
    "name":  "Wilburn Price"
    }

The order isn't important here, because we create the pair of array on every
element if itself. Such as with [a,b,c] array we will have this array via map:

  [a,a], [a,b], [a,c], [b,a], [b,b], [b,c], [c, a], [c, b], [c, a]

Can we elimiate [a,a], [b,b], [c,c] because they are useless. We just need to
put them in `branch` command:

    r.db("foodb")
      .table("users")
      .indexCreate("food-test-idx-2", function (food) {
        return food("favfoods").concatMap(function (favfood) {
          return food("favfoods").map(function (favfood22)    {
            return r.branch(favfood.eq(favfood2),
                [],
                [favfood, favfood2]
                )
          })
        })
      }, {multi: true})

With each element, if we see the value of two elements are same, we return an
empty array, otherwise, we return combination array of them.

# Wrap up

This chapter is quite long. So far we learn about index. We know how to create:

  * Simple index
  * Compound index
  * Multi value index
  * Arbitrary expression index

We also learn how to leverage index to sort, filter data. Two important
transform function you also learn:

  * map:
  * concatMap: 

And finally, by leveraging `map`, you can easily create multi index.
